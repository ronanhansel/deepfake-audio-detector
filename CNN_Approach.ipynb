{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732589001148,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "5sEGjg1roLzC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from scipy.signal import butter, lfilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import Input, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPrxGHEQtpuv"
   },
   "source": [
    "# GET SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 702,
     "status": "ok",
     "timestamp": 1732586423355,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "S6Q9u-Tcy7W1"
   },
   "outputs": [],
   "source": [
    "num_of_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 27666,
     "status": "ok",
     "timestamp": 1732586540405,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "ODAjzwJ0q9XP",
    "outputId": "be0b3070-bbf1-43ff-c1d6-f812c0cbc471"
   },
   "outputs": [],
   "source": [
    "# Function to get all .wav files from a directory\n",
    "def get_wav_files_from_folder(path):\n",
    "    return [os.path.join(path, file) for file in os.listdir(path) if file.endswith('.wav')]\n",
    "\n",
    "# Function to load and display a .wav file\n",
    "def load_and_display_wav(file_path, num_of_samples):\n",
    "    try:\n",
    "        # Load the audio file using librosa\n",
    "        audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "        # Plot the waveform\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.waveshow(audio_data, sr=sample_rate)\n",
    "        plt.title(f'Waveform of {os.path.basename(file_path)}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return audio_data, sample_rate\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or displaying {file_path}: {e}\")\n",
    "\n",
    "# Function to randomly select files from the lists\n",
    "def select_random_files(real_files, fake_files, num_real, num_fake):\n",
    "    if not real_files:\n",
    "        print(\"No real files found!\")\n",
    "    if not fake_files:\n",
    "        print(\"No fake files found!\")\n",
    "\n",
    "    # Select random files from the real and fake lists\n",
    "    selected_real_files = random.sample(real_files, min(num_real, len(real_files)))\n",
    "    selected_fake_files = random.sample(fake_files, min(num_fake, len(fake_files)))\n",
    "\n",
    "    return selected_real_files, selected_fake_files\n",
    "\n",
    "# Paths to the real and fake directories (replace with your actual paths)\n",
    "real_path = \"./content/LibriSeVoc/diffwave\"\n",
    "fake_path = \"./content/LibriSeVoc/gt\"\n",
    "\n",
    "# Load the lists of .wav files from each directory\n",
    "real_files = get_wav_files_from_folder(real_path)\n",
    "fake_files = get_wav_files_from_folder(fake_path)\n",
    "\n",
    "# Get lists of 10 random real and fake file paths\n",
    "random_real_files, random_fake_files = select_random_files(real_files, fake_files, num_real=num_of_samples, num_fake=num_of_samples)\n",
    "\n",
    "Real_Audio = []\n",
    "Fake_Audio = []\n",
    "\n",
    "# # Display the real files\n",
    "# print(\"Displaying random real files:\")\n",
    "# for file in random_real_files:\n",
    "#     Real_Audio.append(load_and_display_wav(file, num_of_samples))\n",
    "\n",
    "# # Display the fake files\n",
    "# print(\"Displaying random fake files:\")\n",
    "# for file in random_fake_files:\n",
    "#     Fake_Audio.append(load_and_display_wav(file, num_of_samples))\n",
    "\n",
    "# print(len(Real_Audio))\n",
    "# print(len(Fake_Audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zeonzo6krBS2",
    "outputId": "36c119f3-4997-47b0-e63b-688f8f8a86ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Audio\n",
      "Fake Audio\n"
     ]
    }
   ],
   "source": [
    "def play_audio(audio_data_list):\n",
    "    for audio_data, sample_rate in audio_data_list:\n",
    "        print(f\"Playing audio with sample rate: {sample_rate} Hz\")\n",
    "        ipd.display(ipd.Audio(data=audio_data, rate=sample_rate))\n",
    "\n",
    "print(\"Real Audio\")\n",
    "play_audio(Real_Audio)\n",
    "print(\"Fake Audio\")\n",
    "play_audio(Fake_Audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h_6czCmrhAG"
   },
   "source": [
    "# *PREPROCESSING FUNCTION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS (Metal Performance Shaders) is available and set the device accordingly\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1732586434405,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "aeM3kWbZrDqH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Check MPS availability and set device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def bandpass_filter(y, sr, lowcut=250, highcut=4000, order=5):\n",
    "    \"\"\"\n",
    "    Applies a bandpass filter to an audio signal.\n",
    "\n",
    "    Args:\n",
    "        y (torch.Tensor): The audio signal as a PyTorch tensor.\n",
    "        sr (int): The sample rate of the audio signal.\n",
    "        lowcut (int, optional): The lower cutoff frequency. Defaults to 250.\n",
    "        highcut (int, optional): The upper cutoff frequency. Defaults to 4000.\n",
    "        order (int, optional): The order of the filter. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The filtered audio signal as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    # Perform the filtering (this part uses scipy and will run on the CPU)\n",
    "    nyq = 0.5 * sr\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y_filtered = lfilter(b, a, y)  # Move to CPU for scipy\n",
    "\n",
    "    # Move the filtered signal back to the original device\n",
    "    return torch.tensor(y_filtered, dtype=y.dtype).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732586435668,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "DB-gIQMss60B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def decrease_low_db(y, sr, threshold_db=-50, target_db=-80):\n",
    "    \"\"\"\n",
    "    Giảm độ lớn của các mẫu âm thanh dưới ngưỡng dB cho trước đến độ to mong muốn,\n",
    "    giữ nguyên thời gian của tín hiệu âm thanh.\n",
    "\n",
    "    :param y: Tín hiệu âm thanh (tensor)\n",
    "    :param sr: Tần số lấy mẫu (Hz)\n",
    "    :param threshold_db: Ngưỡng dB để xác định các mẫu cần giảm độ lớn (ví dụ: -40 dB)\n",
    "    :param target_db: Độ to mong muốn cho các mẫu dưới ngưỡng (ví dụ: -80 dB)\n",
    "    :return: Tín hiệu đã được điều chỉnh (tensor)\n",
    "    \"\"\"\n",
    "    # Calculate the absolute amplitude of the signal\n",
    "    abs_y = torch.abs(y)\n",
    "\n",
    "    # Calculate the reference amplitude (maximum amplitude)\n",
    "    ref_amplitude = torch.max(abs_y) if torch.max(abs_y) > 0 else torch.tensor(1.0, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Calculate the dB level of each sample relative to the reference amplitude\n",
    "    y_db = 20 * torch.log10(abs_y / ref_amplitude + 1e-10)  # Add epsilon to avoid log(0)\n",
    "\n",
    "    # Create a mask for samples below the dB threshold\n",
    "    mask = y_db < threshold_db\n",
    "\n",
    "    # Calculate the desired amplitude for samples below the dB threshold\n",
    "    desired_amplitude = 10 ** (target_db / 20) * ref_amplitude  # Example: -80 dB\n",
    "\n",
    "    # Create a copy of the signal to adjust\n",
    "    y_adjusted = y.clone()\n",
    "\n",
    "    # Reduce the amplitude of samples below the dB threshold\n",
    "    # Avoid division by zero by adding epsilon\n",
    "    y_adjusted[mask] = y_adjusted[mask] / (abs_y[mask] + 1e-10) * desired_amplitude\n",
    "\n",
    "    return y_adjusted  # Convert back to numpy array if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vvvdZeetmNg"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MspLi1niuKFa"
   },
   "source": [
    "# SHOW PROCESSED INSTANCES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CycaecXorgEO"
   },
   "outputs": [],
   "source": [
    "# Filtered_Real_Audio = []\n",
    "# for audio_data, sample_rate in Real_Audio:\n",
    "#     filtered_audio = bandpass_filter(audio_data, sample_rate, lowcut=250, highcut=4000)\n",
    "#     final_audio = decrease_low_db(filtered_audio, sample_rate)\n",
    "#     Filtered_Real_Audio.append(final_audio)\n",
    "\n",
    "# Filtered_Fake_Audio = []\n",
    "# for audio_data, sample_rate in Fake_Audio:\n",
    "#     filtered_audio = bandpass_filter(audio_data, sample_rate, lowcut=250, highcut=4000)\n",
    "#     filtered_audio = decrease_low_db(filtered_audio, sample_rate)\n",
    "#     Filtered_Fake_Audio.append(filtered_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rpqO-OR3xTuC",
    "outputId": "a286c7b2-0bc4-4fac-c848-1cb1033ff653"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def play_and_show_wave_spectrogram(audio_data, sample_rate, title):\n",
    "#     \"\"\"Plays audio, displays waveform, and spectrogram.\"\"\"\n",
    "#     ipd.display(ipd.Audio(data=audio_data, rate=sample_rate))  # Play audio\n",
    "\n",
    "#     # Display waveform\n",
    "#     # plt.figure(figsize=(10, 4))\n",
    "#     # librosa.display.waveshow(audio_data, sr=sample_rate)\n",
    "#     # plt.title(f\"{title} - Waveform\")\n",
    "#     # plt.xlabel(\"Time (s)\")\n",
    "#     # plt.ylabel(\"Amplitude\")\n",
    "#     # plt.tight_layout()\n",
    "#     # plt.show()\n",
    "\n",
    "#     # Display spectrogram\n",
    "#     # plt.figure(figsize=(10, 4))\n",
    "#     # D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_data)), ref=np.max)\n",
    "#     # librosa.display.specshow(D, sr=sample_rate, x_axis='time', y_axis='log')\n",
    "#     # plt.colorbar(format='%+2.0f dB')\n",
    "#     # plt.title(f\"{title} - Spectrogram\")\n",
    "#     # plt.tight_layout()\n",
    "#     # plt.show()\n",
    "\n",
    "# # Play, display waveform, and spectrogram for Filtered_Real_Audio\n",
    "# print(\"Real Audio Display\")\n",
    "# for i, audio_data in enumerate(Filtered_Real_Audio):\n",
    "#     play_and_show_wave_spectrogram(audio_data, Real_Audio[i][1], f\"Filtered Real Audio {i+1}\")\n",
    "\n",
    "# # Play, display waveform, and spectrogram for Filtered_Fake_Audio\n",
    "# print(\"Fake Audio Display\")\n",
    "# for i, audio_data in enumerate(Filtered_Fake_Audio):\n",
    "#     play_and_show_wave_spectrogram(audio_data, Fake_Audio[i][1], f\"Filtered Fake Audio {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV62zb5qtg-L"
   },
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732586540406,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "D92vGPt6bENR",
    "outputId": "8a266eb6-9b0e-4d64-dd04-d089c6d32dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file paths: 21120\n",
      "Test file paths: 5282\n"
     ]
    }
   ],
   "source": [
    "# Define the main data directory\n",
    "\n",
    "# List to hold file paths\n",
    "train_file_paths = []\n",
    "test_file_paths = []\n",
    "\n",
    "label_dict = {\n",
    "    fake_path: 0,\n",
    "    real_path: 1\n",
    "}\n",
    "\n",
    "# Split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Split files in each class directory\n",
    "for class_dir in [fake_path, real_path]:\n",
    "\n",
    "    # Get all file paths for the class\n",
    "    all_files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.endswith('.wav')]\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train_files, test_files = train_test_split(all_files, train_size=train_ratio, random_state=42)\n",
    "\n",
    "    # Append to the respective lists with corresponding labels (class)\n",
    "    for file_path in train_files:\n",
    "        train_file_paths.append((file_path, label_dict[class_dir]))  # Store path and label\n",
    "    for file_path in test_files:\n",
    "        test_file_paths.append((file_path, label_dict[class_dir]))\n",
    "\n",
    "print(f\"Train file paths: {len(train_file_paths)}\")\n",
    "print(f\"Test file paths: {len(test_file_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1732586580946,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "cJYk9AcdF8bO",
    "outputId": "cebbd6cb-685c-4ba7-d758-c85d329b8b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file paths saved to output/train_file_paths.csv\n",
      "Test file paths saved to output/test_file_paths.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# File paths to save the CSVs\n",
    "train_csv = 'output/train_file_paths.csv'\n",
    "test_csv = 'output/test_file_paths.csv'\n",
    "\n",
    "# Save train_file_paths to CSV\n",
    "with open(train_csv, mode='w', newline='') as train_file:\n",
    "    writer = csv.writer(train_file)\n",
    "    writer.writerow(['file_path', 'label'])  # Write the header\n",
    "    for file_path, label in train_file_paths:\n",
    "        writer.writerow([file_path, label])  # Write the file path and label\n",
    "\n",
    "# Save test_file_paths to CSV\n",
    "with open(test_csv, mode='w', newline='') as test_file:\n",
    "    writer = csv.writer(test_file)\n",
    "    writer.writerow(['file_path', 'label'])  # Write the header\n",
    "    for file_path, label in test_file_paths:\n",
    "        writer.writerow([file_path, label])  # Write the file path and label\n",
    "\n",
    "print(f\"Train file paths saved to {train_csv}\")\n",
    "print(f\"Test file paths saved to {test_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuvsA5gzF8bP"
   },
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1732588475361,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "lVT40_iHF8bP"
   },
   "outputs": [],
   "source": [
    "SEGMENT_LENGTH = 1\n",
    "NUM_SEGMENT = 30\n",
    "SR = 24000\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0001\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS (Metal Performance Shaders) is available and set the device accordingly\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1732586600090,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "WooQOFc5F8bP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "# Check MPS availability and set device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def segment_to_spectrogram(segment, sr=24000, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    \"\"\"\n",
    "    Extracts a Mel spectrogram from an audio segment, ensuring execution on the MPS GPU if available.\n",
    "\n",
    "    Args:\n",
    "        segment (torch.Tensor): The audio segment as a PyTorch tensor.\n",
    "        sr (int, optional): The sample rate of the audio segment. Defaults to 24000.\n",
    "        n_fft (int, optional): The size of the FFT. Defaults to 2048.\n",
    "        hop_length (int, optional): The hop length for the STFT. Defaults to 512.\n",
    "        n_mels (int, optional): The number of Mel filterbanks. Defaults to 128.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The Mel spectrogram in decibels (dB).\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the MelSpectrogram transform\n",
    "    mel_spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels\n",
    "    ).to(device)  # Ensure the transform is also on the correct device\n",
    "\n",
    "    # Apply the MelSpectrogram transform\n",
    "    mel_spectrogram = mel_spectrogram(segment)\n",
    "\n",
    "    # Convert to decibels (dB)\n",
    "    spectrogram_db = T.AmplitudeToDB().to(device)  # Move AmplitudeToDB to the device\n",
    "    spectrogram_db = spectrogram_db(mel_spectrogram)\n",
    "\n",
    "    return spectrogram_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1370,
     "status": "ok",
     "timestamp": 1732586719872,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "F2ascfrZF8bP",
    "outputId": "9488f00d-7d2d-4637-cc3c-208264e83ce5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_5551/2508326885.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  waveform = torch.tensor(waveform, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 30 segments\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def extract_segments(audio_file, segment_length=SEGMENT_LENGTH, num_segments=NUM_SEGMENT):\n",
    "    # Load audio file using torchaudio\n",
    "    waveform, sr = torchaudio.load(audio_file)\n",
    "    waveform = bandpass_filter(waveform, sr, lowcut=250, highcut=4000)\n",
    "    waveform = torch.tensor(waveform, dtype=torch.float32).to(device)\n",
    "    waveform = decrease_low_db(waveform, sr)\n",
    "\n",
    "    # Resample if necessary\n",
    "    if sr != SR:\n",
    "        resampler = T.Resample(orig_freq=sr, new_freq=SR)\n",
    "        waveform = resampler(waveform)\n",
    "        sr = SR\n",
    "\n",
    "    # Calculate the total duration in seconds\n",
    "    total_duration = waveform.shape[1] / sr\n",
    "\n",
    "    # Calculate the overlap to ensure exactly num_segments\n",
    "    overlap = (total_duration - segment_length) / (num_segments - 1)\n",
    "\n",
    "    # Convert segment length and overlap to samples\n",
    "    segment_samples = int(segment_length * sr)\n",
    "    overlap_samples = int(overlap * sr)\n",
    "\n",
    "    # Extract the segments\n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * overlap_samples\n",
    "        end_sample = start_sample + segment_samples\n",
    "        segment = waveform[:, start_sample:end_sample]\n",
    "        spectrogram = segment_to_spectrogram(segment)\n",
    "        segments.append(spectrogram)\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "audio_file = './content/LibriSeVoc/gt/19_227_000003_000000.wav'\n",
    "segments = extract_segments(audio_file)\n",
    "print(f\"Extracted {len(segments)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1732588501369,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "DAywUfvsF8bP",
    "outputId": "9f83ba35-702e-413b-f582-f3747dbb7f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              file_path  label\n",
      "0     ./content/LibriSeVoc/gt/60_121082_000096_00000...      0\n",
      "1     ./content/LibriSeVoc/gt/8312_279790_000004_000...      0\n",
      "2     ./content/LibriSeVoc/gt/3168_173564_000017_000...      0\n",
      "3     ./content/LibriSeVoc/gt/7302_86814_000053_0000...      0\n",
      "4     ./content/LibriSeVoc/gt/4813_248638_000012_000...      0\n",
      "...                                                 ...    ...\n",
      "1995  ./content/LibriSeVoc/diffwave/1116_132851_0000...      1\n",
      "1996  ./content/LibriSeVoc/diffwave/87_121553_000086...      1\n",
      "1997  ./content/LibriSeVoc/diffwave/2002_139469_0000...      1\n",
      "1998  ./content/LibriSeVoc/diffwave/1088_129236_0000...      1\n",
      "1999  ./content/LibriSeVoc/diffwave/3168_173565_0000...      1\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV containing train and validation file paths and labels\n",
    "train_csv = './output/train_file_paths.csv'  # Path to the train data CSV\n",
    "\n",
    "train_data = pd.read_csv(train_csv)\n",
    "\n",
    "train_data_head = train_data.head(1000)\n",
    "train_data_tail = train_data.tail(1000)\n",
    "train_data_tail = train_data_tail.reset_index(drop=True)\n",
    "train_data_head = train_data_head.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Concatenate the head and tail along rows (axis=0)\n",
    "demo_train_data = pd.concat([train_data_head, train_data_tail], axis=0)\n",
    "demo_train_data = demo_train_data.reset_index(drop=True)\n",
    "\n",
    "# Display the merged data\n",
    "print(demo_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 495854,
     "status": "ok",
     "timestamp": 1732588999288,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "1zsxc37kF8bQ",
    "outputId": "ecace7f8-593e-4aef-c51b-7986f039fd40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from index 21100\n",
      "Continuing processing from the last checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 16099/21120 [00:00<00:00, 54925.27it/s]/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_5551/2508326885.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  waveform = torch.tensor(waveform, dtype=torch.float32).to(device)\n",
      "/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_5551/97611400.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  file_segments_stacked = torch.stack([torch.tensor(segment, dtype=torch.float32) for segment in file_segments])\n",
      "100%|██████████| 21120/21120 [00:01<00:00, 10957.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 saved at index 21120 to ./output/train_data_checkpoint/train_data_partial_211.pt\n",
      "All segments saved individually.\n",
      "Loading train_data_partial_23.pt\n",
      "Loaded 100 segments from train_data_partial_23.pt\n",
      "Loading train_data_partial_72.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_5551/97611400.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  partial_data = torch.load(os.path.join(os.path.dirname(save_path), partial_file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 segments from train_data_partial_72.pt\n",
      "Loading train_data_partial_81.pt\n",
      "Loaded 100 segments from train_data_partial_81.pt\n",
      "Loading train_data_partial_46.pt\n",
      "Loaded 100 segments from train_data_partial_46.pt\n",
      "Loading train_data_partial_17.pt\n",
      "Loaded 100 segments from train_data_partial_17.pt\n",
      "Loading train_data_partial_2.pt\n",
      "Loaded 100 segments from train_data_partial_2.pt\n",
      "Loading train_data_partial_56.pt\n",
      "Loaded 100 segments from train_data_partial_56.pt\n",
      "Loading train_data_partial_91.pt\n",
      "Loaded 100 segments from train_data_partial_91.pt\n",
      "Loading train_data_partial_62.pt\n",
      "Loaded 100 segments from train_data_partial_62.pt\n",
      "Loading train_data_partial_33.pt\n",
      "Loaded 100 segments from train_data_partial_33.pt\n",
      "Loading train_data_partial_13.pt\n",
      "Loaded 100 segments from train_data_partial_13.pt\n",
      "Loading train_data_partial_42.pt\n",
      "Loaded 100 segments from train_data_partial_42.pt\n",
      "Loading train_data_partial_6.pt\n",
      "Loaded 100 segments from train_data_partial_6.pt\n",
      "Loading train_data_partial_188.pt\n",
      "Loaded 100 segments from train_data_partial_188.pt\n",
      "Loading train_data_partial_76.pt\n",
      "Loaded 100 segments from train_data_partial_76.pt\n",
      "Loading train_data_partial_27.pt\n",
      "Loaded 100 segments from train_data_partial_27.pt\n",
      "Loading train_data_partial_85.pt\n",
      "Loaded 100 segments from train_data_partial_85.pt\n",
      "Loading train_data_partial_95.pt\n",
      "Loaded 100 segments from train_data_partial_95.pt\n",
      "Loading train_data_partial_37.pt\n",
      "Loaded 100 segments from train_data_partial_37.pt\n",
      "Loading train_data_partial_66.pt\n",
      "Loaded 100 segments from train_data_partial_66.pt\n",
      "Loading train_data_partial_209.pt\n",
      "Loaded 100 segments from train_data_partial_209.pt\n",
      "Loading train_data_partial_198.pt\n",
      "Loaded 100 segments from train_data_partial_198.pt\n",
      "Loading train_data_partial_52.pt\n",
      "Loaded 100 segments from train_data_partial_52.pt\n",
      "Loading train_data_partial_12.pt\n",
      "Loaded 100 segments from train_data_partial_12.pt\n",
      "Loading train_data_partial_43.pt\n",
      "Loaded 100 segments from train_data_partial_43.pt\n",
      "Loading train_data_partial_7.pt\n",
      "Loaded 100 segments from train_data_partial_7.pt\n",
      "Loading train_data_partial_189.pt\n",
      "Loaded 100 segments from train_data_partial_189.pt\n",
      "Loading train_data_partial_77.pt\n",
      "Loaded 100 segments from train_data_partial_77.pt\n",
      "Loading train_data_partial_26.pt\n",
      "Loaded 100 segments from train_data_partial_26.pt\n",
      "Loading train_data_partial_84.pt\n",
      "Loaded 100 segments from train_data_partial_84.pt\n",
      "Loading train_data_partial_94.pt\n",
      "Loaded 100 segments from train_data_partial_94.pt\n",
      "Loading train_data_partial_36.pt\n",
      "Loaded 100 segments from train_data_partial_36.pt\n",
      "Loading train_data_partial_67.pt\n",
      "Loaded 100 segments from train_data_partial_67.pt\n",
      "Loading train_data_partial_199.pt\n",
      "Loaded 100 segments from train_data_partial_199.pt\n",
      "Loading train_data_partial_208.pt\n",
      "Loaded 100 segments from train_data_partial_208.pt\n",
      "Loading train_data_partial_53.pt\n",
      "Loaded 100 segments from train_data_partial_53.pt\n",
      "Loading train_data_partial_22.pt\n",
      "Loaded 100 segments from train_data_partial_22.pt\n",
      "Loading train_data_partial_73.pt\n",
      "Loaded 100 segments from train_data_partial_73.pt\n",
      "Loading train_data_partial_80.pt\n",
      "Loaded 100 segments from train_data_partial_80.pt\n",
      "Loading train_data_partial_47.pt\n",
      "Loaded 100 segments from train_data_partial_47.pt\n",
      "Loading train_data_partial_16.pt\n",
      "Loaded 100 segments from train_data_partial_16.pt\n",
      "Loading train_data_partial_3.pt\n",
      "Loaded 100 segments from train_data_partial_3.pt\n",
      "Loading train_data_partial_57.pt\n",
      "Loaded 100 segments from train_data_partial_57.pt\n",
      "Loading train_data_partial_90.pt\n",
      "Loaded 100 segments from train_data_partial_90.pt\n",
      "Loading train_data_partial_63.pt\n",
      "Loaded 100 segments from train_data_partial_63.pt\n",
      "Loading train_data_partial_32.pt\n",
      "Loaded 100 segments from train_data_partial_32.pt\n",
      "Loading train_data_partial_175.pt\n",
      "Loaded 100 segments from train_data_partial_175.pt\n",
      "Loading train_data_partial_124.pt\n",
      "Loaded 100 segments from train_data_partial_124.pt\n",
      "Loading train_data_partial_29.pt\n",
      "Loaded 100 segments from train_data_partial_29.pt\n",
      "Loading train_data_partial_186.pt\n",
      "Loaded 100 segments from train_data_partial_186.pt\n",
      "Loading train_data_partial_78.pt\n",
      "Loaded 100 segments from train_data_partial_78.pt\n",
      "Loading train_data_partial_8.pt\n",
      "Loaded 100 segments from train_data_partial_8.pt\n",
      "Loading train_data_partial_110.pt\n",
      "Loaded 100 segments from train_data_partial_110.pt\n",
      "Loading train_data_partial_141.pt\n",
      "Loaded 100 segments from train_data_partial_141.pt\n",
      "Loading train_data_partial_151.pt\n",
      "Loaded 100 segments from train_data_partial_151.pt\n",
      "Loading train_data_partial_100.pt\n",
      "Loaded 100 segments from train_data_partial_100.pt\n",
      "Loading train_data_partial_68.pt\n",
      "Loaded 100 segments from train_data_partial_68.pt\n",
      "Loading train_data_partial_207.pt\n",
      "Loaded 100 segments from train_data_partial_207.pt\n",
      "Loading train_data_partial_196.pt\n",
      "Loaded 100 segments from train_data_partial_196.pt\n",
      "Loading train_data_partial_39.pt\n",
      "Loaded 100 segments from train_data_partial_39.pt\n",
      "Loading train_data_partial_134.pt\n",
      "Loaded 100 segments from train_data_partial_134.pt\n",
      "Loading train_data_partial_165.pt\n",
      "Loaded 100 segments from train_data_partial_165.pt\n",
      "Loading train_data_partial_145.pt\n",
      "Loaded 100 segments from train_data_partial_145.pt\n",
      "Loading train_data_partial_114.pt\n",
      "Loaded 100 segments from train_data_partial_114.pt\n",
      "Loading train_data_partial_19.pt\n",
      "Loaded 100 segments from train_data_partial_19.pt\n",
      "Loading train_data_partial_48.pt\n",
      "Loaded 100 segments from train_data_partial_48.pt\n",
      "Loading train_data_partial_120.pt\n",
      "Loaded 100 segments from train_data_partial_120.pt\n",
      "Loading train_data_partial_171.pt\n",
      "Loaded 100 segments from train_data_partial_171.pt\n",
      "Loading train_data_partial_182.pt\n",
      "Loaded 100 segments from train_data_partial_182.pt\n",
      "Loading train_data_partial_192.pt\n",
      "Loaded 100 segments from train_data_partial_192.pt\n",
      "Loading train_data_partial_203.pt\n",
      "Loaded 100 segments from train_data_partial_203.pt\n",
      "Loading train_data_partial_161.pt\n",
      "Loaded 100 segments from train_data_partial_161.pt\n",
      "Loading train_data_partial_130.pt\n",
      "Loaded 100 segments from train_data_partial_130.pt\n",
      "Loading train_data_partial_58.pt\n",
      "Loaded 100 segments from train_data_partial_58.pt\n",
      "Loading train_data_partial_104.pt\n",
      "Loaded 100 segments from train_data_partial_104.pt\n",
      "Loading train_data_partial_155.pt\n",
      "Loaded 100 segments from train_data_partial_155.pt\n",
      "Loading train_data_partial_144.pt\n",
      "Loaded 100 segments from train_data_partial_144.pt\n",
      "Loading train_data_partial_115.pt\n",
      "Loaded 100 segments from train_data_partial_115.pt\n",
      "Loading train_data_partial_18.pt\n",
      "Loaded 100 segments from train_data_partial_18.pt\n",
      "Loading train_data_partial_49.pt\n",
      "Loaded 100 segments from train_data_partial_49.pt\n",
      "Loading train_data_partial_121.pt\n",
      "Loaded 100 segments from train_data_partial_121.pt\n",
      "Loading train_data_partial_170.pt\n",
      "Loaded 100 segments from train_data_partial_170.pt\n",
      "Loading train_data_partial_183.pt\n",
      "Loaded 100 segments from train_data_partial_183.pt\n",
      "Loading train_data_partial_202.pt\n",
      "Loaded 100 segments from train_data_partial_202.pt\n",
      "Loading train_data_partial_193.pt\n",
      "Loaded 100 segments from train_data_partial_193.pt\n",
      "Loading train_data_partial_160.pt\n",
      "Loaded 100 segments from train_data_partial_160.pt\n",
      "Loading train_data_partial_131.pt\n",
      "Loaded 100 segments from train_data_partial_131.pt\n",
      "Loading train_data_partial_59.pt\n",
      "Loaded 100 segments from train_data_partial_59.pt\n",
      "Loading train_data_partial_105.pt\n",
      "Loaded 100 segments from train_data_partial_105.pt\n",
      "Loading train_data_partial_154.pt\n",
      "Loaded 100 segments from train_data_partial_154.pt\n",
      "Loading train_data_partial_174.pt\n",
      "Loaded 100 segments from train_data_partial_174.pt\n",
      "Loading train_data_partial_125.pt\n",
      "Loaded 100 segments from train_data_partial_125.pt\n",
      "Loading train_data_partial_28.pt\n",
      "Loaded 100 segments from train_data_partial_28.pt\n",
      "Loading train_data_partial_187.pt\n",
      "Loaded 100 segments from train_data_partial_187.pt\n",
      "Loading train_data_partial_79.pt\n",
      "Loaded 100 segments from train_data_partial_79.pt\n",
      "Loading train_data_partial_9.pt\n",
      "Loaded 100 segments from train_data_partial_9.pt\n",
      "Loading train_data_partial_111.pt\n",
      "Loaded 100 segments from train_data_partial_111.pt\n",
      "Loading train_data_partial_140.pt\n",
      "Loaded 100 segments from train_data_partial_140.pt\n",
      "Loading train_data_partial_150.pt\n",
      "Loaded 100 segments from train_data_partial_150.pt\n",
      "Loading train_data_partial_101.pt\n",
      "Loaded 100 segments from train_data_partial_101.pt\n",
      "Loading train_data_partial_69.pt\n",
      "Loaded 100 segments from train_data_partial_69.pt\n",
      "Loading train_data_partial_197.pt\n",
      "Loaded 100 segments from train_data_partial_197.pt\n",
      "Loading train_data_partial_206.pt\n",
      "Loaded 100 segments from train_data_partial_206.pt\n",
      "Loading train_data_partial_38.pt\n",
      "Loaded 100 segments from train_data_partial_38.pt\n",
      "Loading train_data_partial_135.pt\n",
      "Loaded 100 segments from train_data_partial_135.pt\n",
      "Loading train_data_partial_164.pt\n",
      "Loaded 100 segments from train_data_partial_164.pt\n",
      "Loading train_data_partial_116.pt\n",
      "Loaded 100 segments from train_data_partial_116.pt\n",
      "Loading train_data_partial_147.pt\n",
      "Loaded 100 segments from train_data_partial_147.pt\n",
      "Loading train_data_partial_211.pt\n",
      "Loaded 20 segments from train_data_partial_211.pt\n",
      "Loading train_data_partial_180.pt\n",
      "Loaded 100 segments from train_data_partial_180.pt\n",
      "Loading train_data_partial_173.pt\n",
      "Loaded 100 segments from train_data_partial_173.pt\n",
      "Loading train_data_partial_122.pt\n",
      "Loaded 100 segments from train_data_partial_122.pt\n",
      "Loading train_data_partial_132.pt\n",
      "Loaded 100 segments from train_data_partial_132.pt\n",
      "Loading train_data_partial_163.pt\n",
      "Loaded 100 segments from train_data_partial_163.pt\n",
      "Loading train_data_partial_190.pt\n",
      "Loaded 100 segments from train_data_partial_190.pt\n",
      "Loading train_data_partial_201.pt\n",
      "Loaded 100 segments from train_data_partial_201.pt\n",
      "Loading train_data_partial_157.pt\n",
      "Loaded 100 segments from train_data_partial_157.pt\n",
      "Loading train_data_partial_106.pt\n",
      "Loaded 100 segments from train_data_partial_106.pt\n",
      "Loading train_data_partial_184.pt\n",
      "Loaded 100 segments from train_data_partial_184.pt\n",
      "Loading train_data_partial_126.pt\n",
      "Loaded 100 segments from train_data_partial_126.pt\n",
      "Loading train_data_partial_177.pt\n",
      "Loaded 100 segments from train_data_partial_177.pt\n",
      "Loading train_data_partial_89.pt\n",
      "Loaded 100 segments from train_data_partial_89.pt\n",
      "Loading train_data_partial_143.pt\n",
      "Loaded 100 segments from train_data_partial_143.pt\n",
      "Loading train_data_partial_112.pt\n",
      "Loaded 100 segments from train_data_partial_112.pt\n",
      "Loading train_data_partial_102.pt\n",
      "Loaded 100 segments from train_data_partial_102.pt\n",
      "Loading train_data_partial_153.pt\n",
      "Loaded 100 segments from train_data_partial_153.pt\n",
      "Loading train_data_partial_99.pt\n",
      "Loaded 100 segments from train_data_partial_99.pt\n",
      "Loading train_data_partial_167.pt\n",
      "Loaded 100 segments from train_data_partial_167.pt\n",
      "Loading train_data_partial_136.pt\n",
      "Loaded 100 segments from train_data_partial_136.pt\n",
      "Loading train_data_partial_205.pt\n",
      "Loaded 100 segments from train_data_partial_205.pt\n",
      "Loading train_data_partial_194.pt\n",
      "Loaded 100 segments from train_data_partial_194.pt\n",
      "Loading train_data_partial_185.pt\n",
      "Loaded 100 segments from train_data_partial_185.pt\n",
      "Loading train_data_partial_127.pt\n",
      "Loaded 100 segments from train_data_partial_127.pt\n",
      "Loading train_data_partial_176.pt\n",
      "Loaded 100 segments from train_data_partial_176.pt\n",
      "Loading train_data_partial_88.pt\n",
      "Loaded 100 segments from train_data_partial_88.pt\n",
      "Loading train_data_partial_142.pt\n",
      "Loaded 100 segments from train_data_partial_142.pt\n",
      "Loading train_data_partial_113.pt\n",
      "Loaded 100 segments from train_data_partial_113.pt\n",
      "Loading train_data_partial_103.pt\n",
      "Loaded 100 segments from train_data_partial_103.pt\n",
      "Loading train_data_partial_152.pt\n",
      "Loaded 100 segments from train_data_partial_152.pt\n",
      "Loading train_data_partial_98.pt\n",
      "Loaded 100 segments from train_data_partial_98.pt\n",
      "Loading train_data_partial_166.pt\n",
      "Loaded 100 segments from train_data_partial_166.pt\n",
      "Loading train_data_partial_137.pt\n",
      "Loaded 100 segments from train_data_partial_137.pt\n",
      "Loading train_data_partial_195.pt\n",
      "Loaded 100 segments from train_data_partial_195.pt\n",
      "Loading train_data_partial_204.pt\n",
      "Loaded 100 segments from train_data_partial_204.pt\n",
      "Loading train_data_partial_117.pt\n",
      "Loaded 100 segments from train_data_partial_117.pt\n",
      "Loading train_data_partial_146.pt\n",
      "Loaded 100 segments from train_data_partial_146.pt\n",
      "Loading train_data_partial_181.pt\n",
      "Loaded 100 segments from train_data_partial_181.pt\n",
      "Loading train_data_partial_210.pt\n",
      "Loaded 100 segments from train_data_partial_210.pt\n",
      "Loading train_data_partial_172.pt\n",
      "Loaded 100 segments from train_data_partial_172.pt\n",
      "Loading train_data_partial_123.pt\n",
      "Loaded 100 segments from train_data_partial_123.pt\n",
      "Loading train_data_partial_133.pt\n",
      "Loaded 100 segments from train_data_partial_133.pt\n",
      "Loading train_data_partial_162.pt\n",
      "Loaded 100 segments from train_data_partial_162.pt\n",
      "Loading train_data_partial_200.pt\n",
      "Loaded 100 segments from train_data_partial_200.pt\n",
      "Loading train_data_partial_191.pt\n",
      "Loaded 100 segments from train_data_partial_191.pt\n",
      "Loading train_data_partial_156.pt\n",
      "Loaded 100 segments from train_data_partial_156.pt\n",
      "Loading train_data_partial_107.pt\n",
      "Loaded 100 segments from train_data_partial_107.pt\n",
      "Loading train_data_partial_4.pt\n",
      "Loaded 100 segments from train_data_partial_4.pt\n",
      "Loading train_data_partial_40.pt\n",
      "Loaded 100 segments from train_data_partial_40.pt\n",
      "Loading train_data_partial_11.pt\n",
      "Loaded 100 segments from train_data_partial_11.pt\n",
      "Loading train_data_partial_179.pt\n",
      "Loaded 100 segments from train_data_partial_179.pt\n",
      "Loading train_data_partial_87.pt\n",
      "Loaded 100 segments from train_data_partial_87.pt\n",
      "Loading train_data_partial_128.pt\n",
      "Loaded 100 segments from train_data_partial_128.pt\n",
      "Loading train_data_partial_25.pt\n",
      "Loaded 100 segments from train_data_partial_25.pt\n",
      "Loading train_data_partial_74.pt\n",
      "Loaded 100 segments from train_data_partial_74.pt\n",
      "Loading train_data_partial_64.pt\n",
      "Loaded 100 segments from train_data_partial_64.pt\n",
      "Loading train_data_partial_35.pt\n",
      "Loaded 100 segments from train_data_partial_35.pt\n",
      "Loading train_data_partial_138.pt\n",
      "Loaded 100 segments from train_data_partial_138.pt\n",
      "Loading train_data_partial_97.pt\n",
      "Loaded 100 segments from train_data_partial_97.pt\n",
      "Loading train_data_partial_169.pt\n",
      "Loaded 100 segments from train_data_partial_169.pt\n",
      "Loading train_data_partial_50.pt\n",
      "Loaded 100 segments from train_data_partial_50.pt\n",
      "Loading train_data_partial_83.pt\n",
      "Loaded 100 segments from train_data_partial_83.pt\n",
      "Loading train_data_partial_70.pt\n",
      "Loaded 100 segments from train_data_partial_70.pt\n",
      "Loading train_data_partial_21.pt\n",
      "Loaded 100 segments from train_data_partial_21.pt\n",
      "Loading train_data_partial_149.pt\n",
      "Loaded 100 segments from train_data_partial_149.pt\n",
      "Loading train_data_partial_118.pt\n",
      "Loaded 100 segments from train_data_partial_118.pt\n",
      "Loading train_data_partial_15.pt\n",
      "Loaded 100 segments from train_data_partial_15.pt\n",
      "Loading train_data_partial_44.pt\n",
      "Loaded 100 segments from train_data_partial_44.pt\n",
      "Loading train_data_partial_54.pt\n",
      "Loaded 100 segments from train_data_partial_54.pt\n",
      "Loading train_data_partial_108.pt\n",
      "Loaded 100 segments from train_data_partial_108.pt\n",
      "Loading train_data_partial_159.pt\n",
      "Loaded 100 segments from train_data_partial_159.pt\n",
      "Loading train_data_partial_31.pt\n",
      "Loaded 100 segments from train_data_partial_31.pt\n",
      "Loading train_data_partial_60.pt\n",
      "Loaded 100 segments from train_data_partial_60.pt\n",
      "Loading train_data_partial_93.pt\n",
      "Loaded 100 segments from train_data_partial_93.pt\n",
      "Loading train_data_partial_82.pt\n",
      "Loaded 100 segments from train_data_partial_82.pt\n",
      "Loading train_data_partial_71.pt\n",
      "Loaded 100 segments from train_data_partial_71.pt\n",
      "Loading train_data_partial_20.pt\n",
      "Loaded 100 segments from train_data_partial_20.pt\n",
      "Loading train_data_partial_148.pt\n",
      "Loaded 100 segments from train_data_partial_148.pt\n",
      "Loading train_data_partial_1.pt\n",
      "Loaded 100 segments from train_data_partial_1.pt\n",
      "Loading train_data_partial_119.pt\n",
      "Loaded 100 segments from train_data_partial_119.pt\n",
      "Loading train_data_partial_14.pt\n",
      "Loaded 100 segments from train_data_partial_14.pt\n",
      "Loading train_data_partial_45.pt\n",
      "Loaded 100 segments from train_data_partial_45.pt\n",
      "Loading train_data_partial_55.pt\n",
      "Loaded 100 segments from train_data_partial_55.pt\n",
      "Loading train_data_partial_109.pt\n",
      "Loaded 100 segments from train_data_partial_109.pt\n",
      "Loading train_data_partial_158.pt\n",
      "Loaded 100 segments from train_data_partial_158.pt\n",
      "Loading train_data_partial_30.pt\n",
      "Loaded 100 segments from train_data_partial_30.pt\n",
      "Loading train_data_partial_61.pt\n",
      "Loaded 100 segments from train_data_partial_61.pt\n",
      "Loading train_data_partial_92.pt\n",
      "Loaded 100 segments from train_data_partial_92.pt\n",
      "Loading train_data_partial_5.pt\n",
      "Loaded 100 segments from train_data_partial_5.pt\n",
      "Loading train_data_partial_41.pt\n",
      "Loaded 100 segments from train_data_partial_41.pt\n",
      "Loading train_data_partial_10.pt\n",
      "Loaded 100 segments from train_data_partial_10.pt\n",
      "Loading train_data_partial_178.pt\n",
      "Loaded 100 segments from train_data_partial_178.pt\n",
      "Loading train_data_partial_86.pt\n",
      "Loaded 100 segments from train_data_partial_86.pt\n",
      "Loading train_data_partial_129.pt\n",
      "Loaded 100 segments from train_data_partial_129.pt\n",
      "Loading train_data_partial_24.pt\n",
      "Loaded 100 segments from train_data_partial_24.pt\n",
      "Loading train_data_partial_75.pt\n",
      "Loaded 100 segments from train_data_partial_75.pt\n",
      "Loading train_data_partial_65.pt\n",
      "Loaded 100 segments from train_data_partial_65.pt\n",
      "Loading train_data_partial_34.pt\n",
      "Loaded 100 segments from train_data_partial_34.pt\n",
      "Loading train_data_partial_139.pt\n",
      "Loaded 100 segments from train_data_partial_139.pt\n",
      "Loading train_data_partial_96.pt\n",
      "Loaded 100 segments from train_data_partial_96.pt\n",
      "Loading train_data_partial_168.pt\n",
      "Loaded 100 segments from train_data_partial_168.pt\n",
      "Loading train_data_partial_51.pt\n",
      "Loaded 100 segments from train_data_partial_51.pt\n",
      "Completed loading train data. Saving...\n",
      "Train segments shape: (21020, 30, 128, 47, 1), Train labels shape: (21020,)\n"
     ]
    }
   ],
   "source": [
    "# SAVE_PATH = './output/train_data_checkpoint/train_data_partial'\n",
    "# SAVE_INTERVAL = 100\n",
    "\n",
    "# def load_data(data, segment_length=SEGMENT_LENGTH, num_segments=NUM_SEGMENT, save_interval=SAVE_INTERVAL, save_path=SAVE_PATH, start_index=0):\n",
    "#     segments = []\n",
    "#     labels = []\n",
    "#     # Check for existing partial files\n",
    "#     partial_files = [f for f in os.listdir(os.path.dirname(save_path)) if f.startswith(os.path.basename(save_path)) and f.endswith('.pt')]\n",
    "#     num_partial_files = len(partial_files)\n",
    "#     if start_index == 0:\n",
    "#         start_index = num_partial_files * save_interval\n",
    "#     else:\n",
    "#         start_index = start_index * save_interval\n",
    "#     print(f\"Resuming from index {start_index}\")\n",
    "\n",
    "#     if num_partial_files * save_interval >= len(data):\n",
    "#         print(\"Already finished processing. Merging.\")\n",
    "#         return\n",
    "#     else:\n",
    "#         print(\"Continuing processing from the last checkpoint.\")\n",
    "\n",
    "#     for idx, (_, row) in tqdm(enumerate(data.iterrows()), total=len(data)):\n",
    "#         if idx < start_index:\n",
    "#             continue\n",
    "\n",
    "#         file_path = row['file_path']\n",
    "#         label = row['label']\n",
    "\n",
    "#         # Extract segments from the audio file\n",
    "#         file_segments = extract_segments(file_path, segment_length, num_segments)\n",
    "\n",
    "#         # Stack the segments and convert to torch tensor\n",
    "#         file_segments_stacked = torch.stack([torch.tensor(segment, dtype=torch.float32) for segment in file_segments])\n",
    "\n",
    "#         # Append the stacked segments and their corresponding labels\n",
    "#         segments.append(file_segments_stacked)  # Append the 30 segments as a single element\n",
    "#         labels.append(label)  # Append the label only once per file\n",
    "\n",
    "#         # Save progress every save_interval\n",
    "#         if (idx + 1) % save_interval == 0 or (idx + 1) == len(data):\n",
    "#             partial_path = f\"{save_path}_{int((idx + 1) / save_interval)}.pt\"\n",
    "#             torch.save({'segments': segments, 'labels': labels}, partial_path)\n",
    "#             print(f\"{len(segments)} saved at index {idx + 1} to {partial_path}\")  # More informative print\n",
    "#             segments = []\n",
    "#             labels = []\n",
    "\n",
    "#     print(\"All segments saved individually.\")\n",
    "\n",
    "# def load_saved_segments(data, save_path=SAVE_PATH):\n",
    "#     all_segments = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     # Load all partial files in the SAVE_PATH subdir\n",
    "#     partial_files = [f for f in os.listdir(os.path.dirname(save_path)) if f.startswith(os.path.basename(save_path)) and f.endswith('.pt')]\n",
    "#     for partial_file in partial_files:\n",
    "#         print(f\"Loading {partial_file}\")\n",
    "#         partial_data = torch.load(os.path.join(os.path.dirname(save_path), partial_file))\n",
    "#         print(f\"Loaded {len(partial_data['segments'])} segments from {partial_file}\")\n",
    "#         all_segments.extend(partial_data['segments'])  # Extend directly with the list of stacked segments\n",
    "#         all_labels.extend(partial_data['labels'])  # Extend the labels list\n",
    "\n",
    "#     return torch.stack([segment.to(device) for segment in all_segments]), torch.tensor(all_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "# if os.path.exists(SAVE_PATH + '.pt'):\n",
    "#     # Load train and validation data\n",
    "#     data = torch.load(SAVE_PATH + '.pt')\n",
    "#     train_segments = data['segments']\n",
    "#     train_labels = data['labels']\n",
    "# else:\n",
    "#     # Load the train and validation data\n",
    "#     load_data(train_data)  # Save segments individually\n",
    "#     train_segments, train_labels = load_saved_segments(train_data)  # Load saved segments\n",
    "#     print(\"Completed loading train data. Saving...\")\n",
    "#     # Save the train and validation data\n",
    "#     torch.save({'segments': train_segments, 'labels': train_labels}, f'{SAVE_PATH}.pt')\n",
    "\n",
    "# train_segments = np.array([segment.cpu().numpy() for segment in train_segments])\n",
    "# train_segments = np.transpose(train_segments, (0, 1, 3, 4, 2))\n",
    "# train_labels = train_labels.cpu().numpy()\n",
    "# print(f\"Train segments shape: {train_segments.shape}, Train labels shape: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1862,
     "status": "ok",
     "timestamp": 1732589001147,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "i1udxkc3F8bQ",
    "outputId": "e5cd1344-fb99-4d23-bfbd-82a4873aad07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train segments shape: (21020, 30, 128, 47, 1), Train labels shape: (16816,)\n",
      "Validation segments shape: (4204, 30, 128, 47, 1), Validation labels shape: (4204,)\n"
     ]
    }
   ],
   "source": [
    "# Split the train data further into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_segments, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train segments shape: {train_segments.shape}, Train labels shape: {y_train.shape}\")\n",
    "print(f\"Validation segments shape: {X_val.shape}, Validation labels shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWbTuEvNF8bQ"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1732588358346,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "sXiLYB7NF8bQ",
    "outputId": "f23345d4-6a45-4ca5-871c-0f053277935d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronan/Developer/deepfake-audio-detector/venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/ronan/Developer/deepfake-audio-detector/venv/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2024-11-29 11:43:13.790366: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-11-29 11:43:13.791063: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-11-29 11:43:13.791069: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-11-29 11:43:13.791365: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-29 11:43:13.793715: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), input_shape=input_shape, padding='same', kernel_initializer=initializer),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), padding='same', kernel_initializer=initializer),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=initializer),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.GlobalAveragePooling2D(),  # Outputs a 1D feature vector for each segment\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Assume input_shape is (num_freq_bins, time_steps, 1)\n",
    "input_shape = (128, 47, 1)  # Example input shape based on typical spectrogram size\n",
    "cnn_model = create_cnn_model(input_shape)\n",
    "\n",
    "# Input for multiple segments\n",
    "num_segments = NUM_SEGMENT  # Example number of segments per audio file\n",
    "segment_input = Input(shape=(num_segments, *input_shape))\n",
    "\n",
    "# Apply CNN model to each segment\n",
    "cnn_features = layers.TimeDistributed(cnn_model)(segment_input)  # Shape: (batch, num_segments, feature_dim)\n",
    "# Add LSTM layers (batch_size, timesteps, input_dim)\n",
    "lstm_layer = layers.LSTM(128, return_sequences=True)(cnn_features)\n",
    "lstm_layer = layers.BatchNormalization()(lstm_layer)\n",
    "lstm_layer = layers.LSTM(128, return_sequences=True)(lstm_layer)\n",
    "lstm_layer = layers.BatchNormalization()(lstm_layer)\n",
    "lstm_layer = layers.LSTM(128, return_sequences=False)(lstm_layer)\n",
    "\n",
    "# Classification Layer\n",
    "x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(lstm_layer)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=segment_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">92,672</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m1\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m92,672\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">587,393</span> (2.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m587,393\u001b[0m (2.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">586,881</span> (2.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m586,881\u001b[0m (2.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1732589054217,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "IHZadyWRVoP3"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1732589103930,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "bs7g9q9PVrUy"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w2SMATuVitx"
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1732589143643,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "M2Z-8xnDU93V"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "       filepath='best_model_cnn.keras',  # Path to save the best model\n",
    "       monitor='val_loss',  # Metric to monitor (e.g., val_accuracy, val_loss)\n",
    "       save_best_only=True,  # Only save the best model\n",
    "       mode='min',  # Mode for the monitored metric ('max' for accuracy, 'min' for loss)\n",
    "       verbose=1  # Print messages when saving the model\n",
    "   )\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16816, 30, 128, 47, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqcUaPGXF8bQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 11:43:37.158014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/526\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 237ms/step - accuracy: 0.4978 - loss: 0.9858"
     ]
    }
   ],
   "source": [
    "# Example training\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=128, shuffle=True, validation_data=(X_val, y_val), callbacks=[checkpoint_callback])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
