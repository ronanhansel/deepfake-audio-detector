{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732589001148,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "5sEGjg1roLzC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from scipy.signal import butter, lfilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import Input, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPrxGHEQtpuv"
   },
   "source": [
    "# GET SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 702,
     "status": "ok",
     "timestamp": 1732586423355,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "S6Q9u-Tcy7W1"
   },
   "outputs": [],
   "source": [
    "num_of_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 27666,
     "status": "ok",
     "timestamp": 1732586540405,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "ODAjzwJ0q9XP",
    "outputId": "be0b3070-bbf1-43ff-c1d6-f812c0cbc471"
   },
   "outputs": [],
   "source": [
    "# Function to get all .wav files from a directory\n",
    "def get_wav_files_from_folder(path):\n",
    "    return [os.path.join(path, file) for file in os.listdir(path) if file.endswith('.wav')]\n",
    "\n",
    "# Function to load and display a .wav file\n",
    "def load_and_display_wav(file_path, num_of_samples):\n",
    "    try:\n",
    "        # Load the audio file using librosa\n",
    "        audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "        # Plot the waveform\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.waveshow(audio_data, sr=sample_rate)\n",
    "        plt.title(f'Waveform of {os.path.basename(file_path)}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return audio_data, sample_rate\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or displaying {file_path}: {e}\")\n",
    "\n",
    "# Function to randomly select files from the lists\n",
    "def select_random_files(real_files, fake_files, num_real, num_fake):\n",
    "    if not real_files:\n",
    "        print(\"No real files found!\")\n",
    "    if not fake_files:\n",
    "        print(\"No fake files found!\")\n",
    "\n",
    "    # Select random files from the real and fake lists\n",
    "    selected_real_files = random.sample(real_files, min(num_real, len(real_files)))\n",
    "    selected_fake_files = random.sample(fake_files, min(num_fake, len(fake_files)))\n",
    "\n",
    "    return selected_real_files, selected_fake_files\n",
    "\n",
    "# Paths to the real and fake directories (replace with your actual paths)\n",
    "real_path = \"./content/LibriSeVoc/diffwave\"\n",
    "fake_path = \"./content/LibriSeVoc/gt\"\n",
    "\n",
    "# Load the lists of .wav files from each directory\n",
    "real_files = get_wav_files_from_folder(real_path)\n",
    "fake_files = get_wav_files_from_folder(fake_path)\n",
    "\n",
    "# Get lists of 10 random real and fake file paths\n",
    "random_real_files, random_fake_files = select_random_files(real_files, fake_files, num_real=num_of_samples, num_fake=num_of_samples)\n",
    "\n",
    "Real_Audio = []\n",
    "Fake_Audio = []\n",
    "\n",
    "# # Display the real files\n",
    "# print(\"Displaying random real files:\")\n",
    "# for file in random_real_files:\n",
    "#     Real_Audio.append(load_and_display_wav(file, num_of_samples))\n",
    "\n",
    "# # Display the fake files\n",
    "# print(\"Displaying random fake files:\")\n",
    "# for file in random_fake_files:\n",
    "#     Fake_Audio.append(load_and_display_wav(file, num_of_samples))\n",
    "\n",
    "# print(len(Real_Audio))\n",
    "# print(len(Fake_Audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Zeonzo6krBS2",
    "outputId": "36c119f3-4997-47b0-e63b-688f8f8a86ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Audio\n",
      "Fake Audio\n"
     ]
    }
   ],
   "source": [
    "def play_audio(audio_data_list):\n",
    "    for audio_data, sample_rate in audio_data_list:\n",
    "        print(f\"Playing audio with sample rate: {sample_rate} Hz\")\n",
    "        ipd.display(ipd.Audio(data=audio_data, rate=sample_rate))\n",
    "\n",
    "print(\"Real Audio\")\n",
    "play_audio(Real_Audio)\n",
    "print(\"Fake Audio\")\n",
    "play_audio(Fake_Audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h_6czCmrhAG"
   },
   "source": [
    "# *PREPROCESSING FUNCTION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS (Metal Performance Shaders) is available and set the device accordingly\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1732586434405,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "aeM3kWbZrDqH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Check MPS availability and set device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def bandpass_filter(y, sr, lowcut=250, highcut=4000, order=5):\n",
    "    \"\"\"\n",
    "    Applies a bandpass filter to an audio signal.\n",
    "\n",
    "    Args:\n",
    "        y (torch.Tensor): The audio signal as a PyTorch tensor.\n",
    "        sr (int): The sample rate of the audio signal.\n",
    "        lowcut (int, optional): The lower cutoff frequency. Defaults to 250.\n",
    "        highcut (int, optional): The upper cutoff frequency. Defaults to 4000.\n",
    "        order (int, optional): The order of the filter. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The filtered audio signal as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    # Perform the filtering (this part uses scipy and will run on the CPU)\n",
    "    nyq = 0.5 * sr\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y_filtered = lfilter(b, a, y)  # Move to CPU for scipy\n",
    "\n",
    "    # Move the filtered signal back to the original device\n",
    "    return torch.tensor(y_filtered, dtype=y.dtype).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732586435668,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "DB-gIQMss60B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def decrease_low_db(y, sr, threshold_db=-50, target_db=-80):\n",
    "    \"\"\"\n",
    "    Giảm độ lớn của các mẫu âm thanh dưới ngưỡng dB cho trước đến độ to mong muốn,\n",
    "    giữ nguyên thời gian của tín hiệu âm thanh.\n",
    "\n",
    "    :param y: Tín hiệu âm thanh (tensor)\n",
    "    :param sr: Tần số lấy mẫu (Hz)\n",
    "    :param threshold_db: Ngưỡng dB để xác định các mẫu cần giảm độ lớn (ví dụ: -40 dB)\n",
    "    :param target_db: Độ to mong muốn cho các mẫu dưới ngưỡng (ví dụ: -80 dB)\n",
    "    :return: Tín hiệu đã được điều chỉnh (tensor)\n",
    "    \"\"\"\n",
    "    # Calculate the absolute amplitude of the signal\n",
    "    abs_y = torch.abs(y)\n",
    "\n",
    "    # Calculate the reference amplitude (maximum amplitude)\n",
    "    ref_amplitude = torch.max(abs_y) if torch.max(abs_y) > 0 else torch.tensor(1.0, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Calculate the dB level of each sample relative to the reference amplitude\n",
    "    y_db = 20 * torch.log10(abs_y / ref_amplitude + 1e-10)  # Add epsilon to avoid log(0)\n",
    "\n",
    "    # Create a mask for samples below the dB threshold\n",
    "    mask = y_db < threshold_db\n",
    "\n",
    "    # Calculate the desired amplitude for samples below the dB threshold\n",
    "    desired_amplitude = 10 ** (target_db / 20) * ref_amplitude  # Example: -80 dB\n",
    "\n",
    "    # Create a copy of the signal to adjust\n",
    "    y_adjusted = y.clone()\n",
    "\n",
    "    # Reduce the amplitude of samples below the dB threshold\n",
    "    # Avoid division by zero by adding epsilon\n",
    "    y_adjusted[mask] = y_adjusted[mask] / (abs_y[mask] + 1e-10) * desired_amplitude\n",
    "\n",
    "    return y_adjusted  # Convert back to numpy array if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vvvdZeetmNg"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MspLi1niuKFa"
   },
   "source": [
    "# SHOW PROCESSED INSTANCES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CycaecXorgEO"
   },
   "outputs": [],
   "source": [
    "# Filtered_Real_Audio = []\n",
    "# for audio_data, sample_rate in Real_Audio:\n",
    "#     filtered_audio = bandpass_filter(audio_data, sample_rate, lowcut=250, highcut=4000)\n",
    "#     final_audio = decrease_low_db(filtered_audio, sample_rate)\n",
    "#     Filtered_Real_Audio.append(final_audio)\n",
    "\n",
    "# Filtered_Fake_Audio = []\n",
    "# for audio_data, sample_rate in Fake_Audio:\n",
    "#     filtered_audio = bandpass_filter(audio_data, sample_rate, lowcut=250, highcut=4000)\n",
    "#     filtered_audio = decrease_low_db(filtered_audio, sample_rate)\n",
    "#     Filtered_Fake_Audio.append(filtered_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rpqO-OR3xTuC",
    "outputId": "a286c7b2-0bc4-4fac-c848-1cb1033ff653"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def play_and_show_wave_spectrogram(audio_data, sample_rate, title):\n",
    "#     \"\"\"Plays audio, displays waveform, and spectrogram.\"\"\"\n",
    "#     ipd.display(ipd.Audio(data=audio_data, rate=sample_rate))  # Play audio\n",
    "\n",
    "#     # Display waveform\n",
    "#     # plt.figure(figsize=(10, 4))\n",
    "#     # librosa.display.waveshow(audio_data, sr=sample_rate)\n",
    "#     # plt.title(f\"{title} - Waveform\")\n",
    "#     # plt.xlabel(\"Time (s)\")\n",
    "#     # plt.ylabel(\"Amplitude\")\n",
    "#     # plt.tight_layout()\n",
    "#     # plt.show()\n",
    "\n",
    "#     # Display spectrogram\n",
    "#     # plt.figure(figsize=(10, 4))\n",
    "#     # D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_data)), ref=np.max)\n",
    "#     # librosa.display.specshow(D, sr=sample_rate, x_axis='time', y_axis='log')\n",
    "#     # plt.colorbar(format='%+2.0f dB')\n",
    "#     # plt.title(f\"{title} - Spectrogram\")\n",
    "#     # plt.tight_layout()\n",
    "#     # plt.show()\n",
    "\n",
    "# # Play, display waveform, and spectrogram for Filtered_Real_Audio\n",
    "# print(\"Real Audio Display\")\n",
    "# for i, audio_data in enumerate(Filtered_Real_Audio):\n",
    "#     play_and_show_wave_spectrogram(audio_data, Real_Audio[i][1], f\"Filtered Real Audio {i+1}\")\n",
    "\n",
    "# # Play, display waveform, and spectrogram for Filtered_Fake_Audio\n",
    "# print(\"Fake Audio Display\")\n",
    "# for i, audio_data in enumerate(Filtered_Fake_Audio):\n",
    "#     play_and_show_wave_spectrogram(audio_data, Fake_Audio[i][1], f\"Filtered Fake Audio {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV62zb5qtg-L"
   },
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732586540406,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "D92vGPt6bENR",
    "outputId": "8a266eb6-9b0e-4d64-dd04-d089c6d32dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file paths: 21120\n",
      "Test file paths: 5282\n"
     ]
    }
   ],
   "source": [
    "# Define the main data directory\n",
    "\n",
    "# List to hold file paths\n",
    "train_file_paths = []\n",
    "test_file_paths = []\n",
    "\n",
    "label_dict = {\n",
    "    fake_path: 0,\n",
    "    real_path: 1\n",
    "}\n",
    "\n",
    "# Split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Split files in each class directory\n",
    "for class_dir in [fake_path, real_path]:\n",
    "\n",
    "    # Get all file paths for the class\n",
    "    all_files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.endswith('.wav')]\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train_files, test_files = train_test_split(all_files, train_size=train_ratio, random_state=42)\n",
    "\n",
    "    # Append to the respective lists with corresponding labels (class)\n",
    "    for file_path in train_files:\n",
    "        train_file_paths.append((file_path, label_dict[class_dir]))  # Store path and label\n",
    "    for file_path in test_files:\n",
    "        test_file_paths.append((file_path, label_dict[class_dir]))\n",
    "\n",
    "print(f\"Train file paths: {len(train_file_paths)}\")\n",
    "print(f\"Test file paths: {len(test_file_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1732586580946,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "cJYk9AcdF8bO",
    "outputId": "cebbd6cb-685c-4ba7-d758-c85d329b8b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file paths saved to output/train_file_paths.csv\n",
      "Test file paths saved to output/test_file_paths.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# File paths to save the CSVs\n",
    "train_csv = 'output/train_file_paths.csv'\n",
    "test_csv = 'output/test_file_paths.csv'\n",
    "\n",
    "# Save train_file_paths to CSV\n",
    "with open(train_csv, mode='w', newline='') as train_file:\n",
    "    writer = csv.writer(train_file)\n",
    "    writer.writerow(['file_path', 'label'])  # Write the header\n",
    "    for file_path, label in train_file_paths:\n",
    "        writer.writerow([file_path, label])  # Write the file path and label\n",
    "\n",
    "# Save test_file_paths to CSV\n",
    "with open(test_csv, mode='w', newline='') as test_file:\n",
    "    writer = csv.writer(test_file)\n",
    "    writer.writerow(['file_path', 'label'])  # Write the header\n",
    "    for file_path, label in test_file_paths:\n",
    "        writer.writerow([file_path, label])  # Write the file path and label\n",
    "\n",
    "print(f\"Train file paths saved to {train_csv}\")\n",
    "print(f\"Test file paths saved to {test_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuvsA5gzF8bP"
   },
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1732588475361,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "lVT40_iHF8bP"
   },
   "outputs": [],
   "source": [
    "SEGMENT_LENGTH = 1\n",
    "NUM_SEGMENT = 30\n",
    "SR = 24000\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0001\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS (Metal Performance Shaders) is available and set the device accordingly\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1732586600090,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "WooQOFc5F8bP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "# Check MPS availability and set device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def segment_to_spectrogram(segment, sr=24000, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    \"\"\"\n",
    "    Extracts a Mel spectrogram from an audio segment, ensuring execution on the MPS GPU if available.\n",
    "\n",
    "    Args:\n",
    "        segment (torch.Tensor): The audio segment as a PyTorch tensor.\n",
    "        sr (int, optional): The sample rate of the audio segment. Defaults to 24000.\n",
    "        n_fft (int, optional): The size of the FFT. Defaults to 2048.\n",
    "        hop_length (int, optional): The hop length for the STFT. Defaults to 512.\n",
    "        n_mels (int, optional): The number of Mel filterbanks. Defaults to 128.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The Mel spectrogram in decibels (dB).\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the MelSpectrogram transform\n",
    "    mel_spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels\n",
    "    ).to(device)  # Ensure the transform is also on the correct device\n",
    "\n",
    "    # Apply the MelSpectrogram transform\n",
    "    mel_spectrogram = mel_spectrogram(segment)\n",
    "\n",
    "    # Convert to decibels (dB)\n",
    "    spectrogram_db = T.AmplitudeToDB().to(device)  # Move AmplitudeToDB to the device\n",
    "    spectrogram_db = spectrogram_db(mel_spectrogram)\n",
    "\n",
    "    return spectrogram_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1370,
     "status": "ok",
     "timestamp": 1732586719872,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "F2ascfrZF8bP",
    "outputId": "9488f00d-7d2d-4637-cc3c-208264e83ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 30 segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_51830/2641378940.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  waveform = torch.tensor(waveform, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def extract_segments(audio_file, segment_length=SEGMENT_LENGTH, num_segments=NUM_SEGMENT):\n",
    "    # Load audio file using torchaudio\n",
    "    waveform, sr = torchaudio.load(audio_file)\n",
    "    # waveform = bandpass_filter(waveform, sr, lowcut=250, highcut=4000)\n",
    "    waveform = torch.tensor(waveform, dtype=torch.float32).to(device)\n",
    "    # waveform = decrease_low_db(waveform, sr)\n",
    "\n",
    "    # Resample if necessary\n",
    "    if sr != SR:\n",
    "        resampler = T.Resample(orig_freq=sr, new_freq=SR)\n",
    "        waveform = resampler(waveform)\n",
    "        sr = SR\n",
    "\n",
    "    # Calculate the total duration in seconds\n",
    "    total_duration = waveform.shape[1] / sr\n",
    "\n",
    "    # Calculate the overlap to ensure exactly num_segments\n",
    "    overlap = (total_duration - segment_length) / (num_segments - 1)\n",
    "\n",
    "    # Convert segment length and overlap to samples\n",
    "    segment_samples = int(segment_length * sr)\n",
    "    overlap_samples = int(overlap * sr)\n",
    "\n",
    "    # Extract the segments\n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * overlap_samples\n",
    "        end_sample = start_sample + segment_samples\n",
    "        segment = waveform[:, start_sample:end_sample]\n",
    "        spectrogram = segment_to_spectrogram(segment)\n",
    "        segments.append(spectrogram)\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "audio_file = './content/LibriSeVoc/gt/19_227_000003_000000.wav'\n",
    "segments = extract_segments(audio_file)\n",
    "print(f\"Extracted {len(segments)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1732588501369,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "DAywUfvsF8bP",
    "outputId": "9f83ba35-702e-413b-f582-f3747dbb7f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              file_path  label\n",
      "0     ./content/LibriSeVoc/gt/3879_173592_000017_000...      0\n",
      "1     ./content/LibriSeVoc/gt/2817_142380_000021_000...      0\n",
      "2     ./content/LibriSeVoc/gt/7059_77897_000013_0000...      0\n",
      "3     ./content/LibriSeVoc/gt/3857_180923_000017_000...      0\n",
      "4     ./content/LibriSeVoc/gt/3440_171009_000067_000...      0\n",
      "...                                                 ...    ...\n",
      "1995  ./content/LibriSeVoc/diffwave/3982_182255_0000...      1\n",
      "1996  ./content/LibriSeVoc/diffwave/6272_70171_00002...      1\n",
      "1997  ./content/LibriSeVoc/diffwave/374_180298_00000...      1\n",
      "1998  ./content/LibriSeVoc/diffwave/4788_94904_00000...      1\n",
      "1999  ./content/LibriSeVoc/diffwave/730_358_000001_0...      1\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV containing train and validation file paths and labels\n",
    "train_csv = './output/test_file_paths.csv'  # Path to the train data CSV\n",
    "\n",
    "train_data = pd.read_csv(train_csv)\n",
    "\n",
    "train_data_head = train_data.head(1000)\n",
    "train_data_tail = train_data.tail(1000)\n",
    "train_data_tail = train_data_tail.reset_index(drop=True)\n",
    "train_data_head = train_data_head.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Concatenate the head and tail along rows (axis=0)\n",
    "demo_train_data = pd.concat([train_data_head, train_data_tail], axis=0)\n",
    "demo_train_data = demo_train_data.reset_index(drop=True)\n",
    "\n",
    "# Display the merged data\n",
    "print(demo_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 495854,
     "status": "ok",
     "timestamp": 1732588999288,
     "user": {
      "displayName": "Tuấn Nam Đỗ",
      "userId": "12452333077463821897"
     },
     "user_tz": -420
    },
    "id": "1zsxc37kF8bQ",
    "outputId": "ecace7f8-593e-4aef-c51b-7986f039fd40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and saving train data:  5282\n",
      "Resuming from index 1000\n",
      "Continuing processing from the last checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5282 [00:00<?, ?it/s]/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_51830/2641378940.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  waveform = torch.tensor(waveform, dtype=torch.float32).to(device)\n",
      "/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_51830/3948697964.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  file_segments_stacked = torch.stack([torch.tensor(segment, dtype=torch.float32) for segment in file_segments])\n",
      " 19%|█▉        | 1001/5282 [00:00<00:00, 7868.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 1100 to ./output/test_data_checkpoint/test_data_partial_1100.pt\n",
      "100 saved at index 1200 to ./output/test_data_checkpoint/test_data_partial_1200.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1282/5282 [00:20<01:21, 48.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 1300 to ./output/test_data_checkpoint/test_data_partial_1300.pt\n",
      "100 saved at index 1400 to ./output/test_data_checkpoint/test_data_partial_1400.pt\n",
      "100 saved at index 1500 to ./output/test_data_checkpoint/test_data_partial_1500.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1597/5282 [00:40<02:18, 26.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 1600 to ./output/test_data_checkpoint/test_data_partial_1600.pt\n",
      "100 saved at index 1700 to ./output/test_data_checkpoint/test_data_partial_1700.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 1777/5282 [00:53<02:50, 20.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 1800 to ./output/test_data_checkpoint/test_data_partial_1800.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1885/5282 [01:01<03:10, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 1900 to ./output/test_data_checkpoint/test_data_partial_1900.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2002/5282 [01:09<03:17, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2000 to ./output/test_data_checkpoint/test_data_partial_2000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2101/5282 [01:16<03:31, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2100 to ./output/test_data_checkpoint/test_data_partial_2100.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2203/5282 [01:23<04:25, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2200 to ./output/test_data_checkpoint/test_data_partial_2200.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 2302/5282 [01:31<07:11,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2300 to ./output/test_data_checkpoint/test_data_partial_2300.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 2401/5282 [01:38<03:55, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2400 to ./output/test_data_checkpoint/test_data_partial_2400.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2501/5282 [01:45<04:04, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2500 to ./output/test_data_checkpoint/test_data_partial_2500.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2601/5282 [01:52<04:03, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2600 to ./output/test_data_checkpoint/test_data_partial_2600.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2701/5282 [01:58<03:39, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2700 to ./output/test_data_checkpoint/test_data_partial_2700.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2802/5282 [02:05<03:27, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2800 to ./output/test_data_checkpoint/test_data_partial_2800.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 2902/5282 [02:12<02:34, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 2900 to ./output/test_data_checkpoint/test_data_partial_2900.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3003/5282 [02:19<03:06, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3000 to ./output/test_data_checkpoint/test_data_partial_3000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 3101/5282 [02:26<03:14, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3100 to ./output/test_data_checkpoint/test_data_partial_3100.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3202/5282 [02:33<02:38, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3200 to ./output/test_data_checkpoint/test_data_partial_3200.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3302/5282 [02:38<02:00, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3300 to ./output/test_data_checkpoint/test_data_partial_3300.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3402/5282 [02:43<01:54, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3400 to ./output/test_data_checkpoint/test_data_partial_3400.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 3503/5282 [02:48<01:55, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3500 to ./output/test_data_checkpoint/test_data_partial_3500.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3603/5282 [02:53<01:37, 17.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3600 to ./output/test_data_checkpoint/test_data_partial_3600.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3703/5282 [02:59<02:15, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3700 to ./output/test_data_checkpoint/test_data_partial_3700.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3802/5282 [03:06<02:25, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3800 to ./output/test_data_checkpoint/test_data_partial_3800.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3901/5282 [03:15<02:42,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 3900 to ./output/test_data_checkpoint/test_data_partial_3900.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 4002/5282 [03:21<01:19, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4000 to ./output/test_data_checkpoint/test_data_partial_4000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4100/5282 [03:29<01:33, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4100 to ./output/test_data_checkpoint/test_data_partial_4100.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 4202/5282 [03:38<01:52,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4200 to ./output/test_data_checkpoint/test_data_partial_4200.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 4302/5282 [03:46<01:55,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4300 to ./output/test_data_checkpoint/test_data_partial_4300.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4403/5282 [03:54<01:03, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4400 to ./output/test_data_checkpoint/test_data_partial_4400.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4501/5282 [04:00<01:06, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4500 to ./output/test_data_checkpoint/test_data_partial_4500.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4603/5282 [04:08<00:53, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4600 to ./output/test_data_checkpoint/test_data_partial_4600.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4701/5282 [04:15<00:55, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4700 to ./output/test_data_checkpoint/test_data_partial_4700.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4801/5282 [04:22<00:40, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4800 to ./output/test_data_checkpoint/test_data_partial_4800.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4902/5282 [04:30<00:31, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 4900 to ./output/test_data_checkpoint/test_data_partial_4900.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 5002/5282 [04:37<00:24, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 5000 to ./output/test_data_checkpoint/test_data_partial_5000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 5103/5282 [04:43<00:13, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 5100 to ./output/test_data_checkpoint/test_data_partial_5100.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 5201/5282 [04:50<00:08,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 saved at index 5200 to ./output/test_data_checkpoint/test_data_partial_5200.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5282/5282 [04:56<00:00, 17.80it/s]\n",
      "/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_51830/3948697964.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  partial_data = torch.load(os.path.join(os.path.dirname(save_path), partial_file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 saved at index 5282 to ./output/test_data_checkpoint/test_data_partial_5282.pt\n",
      "All segments saved individually.\n",
      "Loading test_data_partial_3000.pt\n",
      "Loaded 100 segments from test_data_partial_3000.pt\n",
      "Loading test_data_partial_2600.pt\n",
      "Loaded 100 segments from test_data_partial_2600.pt\n",
      "Loading test_data_partial_100.pt\n",
      "Loaded 100 segments from test_data_partial_100.pt\n",
      "Loading test_data_partial_5100.pt\n",
      "Loaded 100 segments from test_data_partial_5100.pt\n",
      "Loading test_data_partial_4700.pt\n",
      "Loaded 100 segments from test_data_partial_4700.pt\n",
      "Loading test_data_partial_1000.pt\n",
      "Loaded 100 segments from test_data_partial_1000.pt\n",
      "Loading test_data_partial_1100.pt\n",
      "Loaded 100 segments from test_data_partial_1100.pt\n",
      "Loading test_data_partial_4600.pt\n",
      "Loaded 100 segments from test_data_partial_4600.pt\n",
      "Loading test_data_partial_5000.pt\n",
      "Loaded 100 segments from test_data_partial_5000.pt\n",
      "Loading test_data_partial_2700.pt\n",
      "Loaded 100 segments from test_data_partial_2700.pt\n",
      "Loading test_data_partial_3100.pt\n",
      "Loaded 100 segments from test_data_partial_3100.pt\n",
      "Loading test_data_partial_4100.pt\n",
      "Loaded 100 segments from test_data_partial_4100.pt\n",
      "Loading test_data_partial_1600.pt\n",
      "Loaded 100 segments from test_data_partial_1600.pt\n",
      "Loading test_data_partial_3600.pt\n",
      "Loaded 100 segments from test_data_partial_3600.pt\n",
      "Loading test_data_partial_2000.pt\n",
      "Loaded 100 segments from test_data_partial_2000.pt\n",
      "Loading test_data_partial_700.pt\n",
      "Loaded 100 segments from test_data_partial_700.pt\n",
      "Loading test_data_partial_600.pt\n",
      "Loaded 100 segments from test_data_partial_600.pt\n",
      "Loading test_data_partial_2100.pt\n",
      "Loaded 100 segments from test_data_partial_2100.pt\n",
      "Loading test_data_partial_3700.pt\n",
      "Loaded 100 segments from test_data_partial_3700.pt\n",
      "Loading test_data_partial_1700.pt\n",
      "Loaded 100 segments from test_data_partial_1700.pt\n",
      "Loading test_data_partial_4000.pt\n",
      "Loaded 100 segments from test_data_partial_4000.pt\n",
      "Loading test_data_partial_900.pt\n",
      "Loaded 100 segments from test_data_partial_900.pt\n",
      "Loading test_data_partial_3800.pt\n",
      "Loaded 100 segments from test_data_partial_3800.pt\n",
      "Loading test_data_partial_1400.pt\n",
      "Loaded 100 segments from test_data_partial_1400.pt\n",
      "Loading test_data_partial_4300.pt\n",
      "Loaded 100 segments from test_data_partial_4300.pt\n",
      "Loading test_data_partial_500.pt\n",
      "Loaded 100 segments from test_data_partial_500.pt\n",
      "Loading test_data_partial_2200.pt\n",
      "Loaded 100 segments from test_data_partial_2200.pt\n",
      "Loading test_data_partial_3400.pt\n",
      "Loaded 100 segments from test_data_partial_3400.pt\n",
      "Loading test_data_partial_1800.pt\n",
      "Loaded 100 segments from test_data_partial_1800.pt\n",
      "Loading test_data_partial_1900.pt\n",
      "Loaded 100 segments from test_data_partial_1900.pt\n",
      "Loading test_data_partial_3500.pt\n",
      "Loaded 100 segments from test_data_partial_3500.pt\n",
      "Loading test_data_partial_2300.pt\n",
      "Loaded 100 segments from test_data_partial_2300.pt\n",
      "Loading test_data_partial_400.pt\n",
      "Loaded 100 segments from test_data_partial_400.pt\n",
      "Loading test_data_partial_4200.pt\n",
      "Loaded 100 segments from test_data_partial_4200.pt\n",
      "Loading test_data_partial_1500.pt\n",
      "Loaded 100 segments from test_data_partial_1500.pt\n",
      "Loading test_data_partial_3900.pt\n",
      "Loaded 100 segments from test_data_partial_3900.pt\n",
      "Loading test_data_partial_800.pt\n",
      "Loaded 100 segments from test_data_partial_800.pt\n",
      "Loading test_data_partial_300.pt\n",
      "Loaded 100 segments from test_data_partial_300.pt\n",
      "Loading test_data_partial_2400.pt\n",
      "Loaded 100 segments from test_data_partial_2400.pt\n",
      "Loading test_data_partial_3200.pt\n",
      "Loaded 100 segments from test_data_partial_3200.pt\n",
      "Loading test_data_partial_4900.pt\n",
      "Loaded 100 segments from test_data_partial_4900.pt\n",
      "Loading test_data_partial_2800.pt\n",
      "Loaded 100 segments from test_data_partial_2800.pt\n",
      "Loading test_data_partial_1200.pt\n",
      "Loaded 100 segments from test_data_partial_1200.pt\n",
      "Loading test_data_partial_4500.pt\n",
      "Loaded 100 segments from test_data_partial_4500.pt\n",
      "Loading test_data_partial_5200.pt\n",
      "Loaded 100 segments from test_data_partial_5200.pt\n",
      "Loading test_data_partial_4400.pt\n",
      "Loaded 100 segments from test_data_partial_4400.pt\n",
      "Loading test_data_partial_1300.pt\n",
      "Loaded 100 segments from test_data_partial_1300.pt\n",
      "Loading test_data_partial_2900.pt\n",
      "Loaded 100 segments from test_data_partial_2900.pt\n",
      "Loading test_data_partial_4800.pt\n",
      "Loaded 100 segments from test_data_partial_4800.pt\n",
      "Loading test_data_partial_3300.pt\n",
      "Loaded 100 segments from test_data_partial_3300.pt\n",
      "Loading test_data_partial_2500.pt\n",
      "Loaded 100 segments from test_data_partial_2500.pt\n",
      "Loading test_data_partial_5282.pt\n",
      "Loaded 82 segments from test_data_partial_5282.pt\n",
      "Loading test_data_partial_200.pt\n",
      "Loaded 100 segments from test_data_partial_200.pt\n",
      "Finished loading, stacking loaded tensors...\n",
      "Completed loading train data. Saving...\n",
      "Train segments shape: (5282, 30, 128, 47, 1), Train labels shape: (5282,)\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = './output/test_data_checkpoint/test_data_partial'\n",
    "SAVE_INTERVAL = 100\n",
    "\n",
    "def load_data(data, segment_length=SEGMENT_LENGTH, num_segments=NUM_SEGMENT, save_interval=SAVE_INTERVAL, save_path=SAVE_PATH, start_index=0):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    # Check for existing partial files\n",
    "    partial_files = [f for f in os.listdir(os.path.dirname(save_path)) if f.startswith(os.path.basename(save_path)) and f.endswith('.pt')]\n",
    "    num_partial_files = len(partial_files)\n",
    "    if start_index == 0:\n",
    "        start_index = num_partial_files * save_interval\n",
    "    else:\n",
    "        start_index = start_index * save_interval\n",
    "    print(f\"Resuming from index {start_index}\")\n",
    "\n",
    "    if num_partial_files * save_interval >= len(data): # Check if all files have been processed\n",
    "        print(\"Already finished processing. Merging.\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Continuing processing from the last checkpoint.\")\n",
    "\n",
    "    for idx, (_, row) in tqdm(enumerate(data.iterrows()), total=len(data)):\n",
    "        if idx < start_index:\n",
    "            continue\n",
    "\n",
    "        file_path = row['file_path']\n",
    "        label = row['label']\n",
    "\n",
    "        # Extract segments from the audio file\n",
    "        file_segments = extract_segments(file_path, segment_length, num_segments)\n",
    "\n",
    "        # Stack the segments and convert to torch tensor\n",
    "        file_segments_stacked = torch.stack([torch.tensor(segment, dtype=torch.float32) for segment in file_segments])\n",
    "\n",
    "        # Append the stacked segments and their corresponding labels\n",
    "        segments.append(file_segments_stacked)  # Append the 30 segments as a single element\n",
    "        labels.append(label)  # Append the label only once per file\n",
    "\n",
    "        # Save progress every save_interval\n",
    "        if (idx + 1) % save_interval == 0 or (idx + 1) == len(data):\n",
    "            partial_path = f\"{save_path}_{int((idx + 1))}.pt\"\n",
    "            torch.save({'segments': segments, 'labels': labels}, partial_path)\n",
    "            print(f\"{len(segments)} saved at index {idx + 1} to {partial_path}\")  # More informative print\n",
    "            segments = []\n",
    "            labels = []\n",
    "\n",
    "    print(\"All segments saved individually.\")\n",
    "\n",
    "def load_saved_segments(data, save_path=SAVE_PATH):\n",
    "    all_segments = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Load all partial files in the SAVE_PATH subdir\n",
    "    partial_files = [f for f in os.listdir(os.path.dirname(save_path)) if f.startswith(os.path.basename(save_path)) and f.endswith('.pt')]\n",
    "    for partial_file in partial_files:\n",
    "        print(f\"Loading {partial_file}\")\n",
    "        partial_data = torch.load(os.path.join(os.path.dirname(save_path), partial_file))\n",
    "        print(f\"Loaded {len(partial_data['segments'])} segments from {partial_file}\")\n",
    "        all_segments.extend(partial_data['segments'])  # Extend directly with the list of stacked segments\n",
    "        all_labels.extend(partial_data['labels'])  # Extend the labels list\n",
    "    print(\"Finished loading, stacking loaded tensors...\")\n",
    "    return torch.stack([segment.cpu() for segment in all_segments]), torch.tensor(all_labels, dtype=torch.float32).cpu()\n",
    "\n",
    "\n",
    "if os.path.exists(SAVE_PATH + '.pt'):\n",
    "    # Load train and validation data\n",
    "    data = torch.load(SAVE_PATH + '.pt')\n",
    "    train_segments = data['segments']\n",
    "    print(f\"Loaded {len(train_segments)} segments\")\n",
    "    train_labels = data['labels']\n",
    "else:\n",
    "    print(\"Loading and saving train data: \", len(train_data))\n",
    "    # Load the train and validation data\n",
    "    load_data(train_data)  # Save segments individually\n",
    "    train_segments, train_labels = load_saved_segments(train_data)  # Load and combine saved segments\n",
    "    print(\"Completed loading train data. Saving...\")\n",
    "    # Save the train and validation data\n",
    "    torch.save({'segments': train_segments, 'labels': train_labels}, f'{SAVE_PATH}.pt')\n",
    "\n",
    "train_segments = np.array([segment.cpu().numpy() for segment in train_segments])\n",
    "train_segments = np.transpose(train_segments, (0, 1, 3, 4, 2))\n",
    "train_labels = train_labels.cpu().numpy().astype(int)\n",
    "print(f\"Train segments shape: {train_segments.shape}, Train labels shape: {train_labels.shape}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
