{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./output/data/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_path', 'sampling_rate', 'label', 'mfcc_1_mean', 'mfcc_2_mean',\n",
       "       'mfcc_3_mean', 'mfcc_4_mean', 'mfcc_5_mean', 'mfcc_6_mean',\n",
       "       'mfcc_7_mean', 'mfcc_8_mean', 'mfcc_9_mean', 'mfcc_10_mean',\n",
       "       'mfcc_11_mean', 'mfcc_12_mean', 'mfcc_13_mean', 'chroma_1_mean',\n",
       "       'chroma_2_mean', 'chroma_3_mean', 'zcr_mean',\n",
       "       'spectral_contrast_1_mean', 'spectral_contrast_2_mean',\n",
       "       'spectral_contrast_3_mean', 'spectral_contrast_4_mean',\n",
       "       'spectral_contrast_5_mean', 'spectral_contrast_6_mean',\n",
       "       'spectral_centroid_mean', 'spectral_bandwidth_mean',\n",
       "       'spectral_rolloff_mean', 'lpc_1_mean', 'lpc_2_mean', 'lpc_3_mean',\n",
       "       'lpc_4_mean', 'lpc_5_mean', 'lpc_6_mean', 'lpc_7_mean', 'lpc_8_mean',\n",
       "       'lpc_9_mean', 'lpc_10_mean', 'lpc_11_mean', 'lpc_12_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/d7p0zrqx7l3f7dwplj0g_b040000gn/T/ipykernel_16846/3452172015.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['label'] = data['label'].replace({'fake': 0, 'real': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>mfcc_1_mean</th>\n",
       "      <th>mfcc_2_mean</th>\n",
       "      <th>mfcc_3_mean</th>\n",
       "      <th>mfcc_4_mean</th>\n",
       "      <th>mfcc_5_mean</th>\n",
       "      <th>mfcc_6_mean</th>\n",
       "      <th>mfcc_7_mean</th>\n",
       "      <th>mfcc_8_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>lpc_3_mean</th>\n",
       "      <th>lpc_4_mean</th>\n",
       "      <th>lpc_5_mean</th>\n",
       "      <th>lpc_6_mean</th>\n",
       "      <th>lpc_7_mean</th>\n",
       "      <th>lpc_8_mean</th>\n",
       "      <th>lpc_9_mean</th>\n",
       "      <th>lpc_10_mean</th>\n",
       "      <th>lpc_11_mean</th>\n",
       "      <th>lpc_12_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24000</td>\n",
       "      <td>0</td>\n",
       "      <td>-392.408060</td>\n",
       "      <td>122.706493</td>\n",
       "      <td>4.529471</td>\n",
       "      <td>-1.131724</td>\n",
       "      <td>10.133050</td>\n",
       "      <td>-7.359573</td>\n",
       "      <td>-12.236763</td>\n",
       "      <td>-11.748826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206947</td>\n",
       "      <td>0.242434</td>\n",
       "      <td>0.083058</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.048853</td>\n",
       "      <td>0.049655</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>-0.013775</td>\n",
       "      <td>0.056669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "      <td>-288.633987</td>\n",
       "      <td>150.553761</td>\n",
       "      <td>-51.823300</td>\n",
       "      <td>9.575870</td>\n",
       "      <td>16.140331</td>\n",
       "      <td>-25.634484</td>\n",
       "      <td>-9.063233</td>\n",
       "      <td>-13.583262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942317</td>\n",
       "      <td>0.165730</td>\n",
       "      <td>-0.168018</td>\n",
       "      <td>-0.083517</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.079114</td>\n",
       "      <td>0.045597</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>-0.022306</td>\n",
       "      <td>0.027391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "      <td>-321.349296</td>\n",
       "      <td>128.728553</td>\n",
       "      <td>-45.678164</td>\n",
       "      <td>16.015681</td>\n",
       "      <td>2.248679</td>\n",
       "      <td>-36.931314</td>\n",
       "      <td>-16.453398</td>\n",
       "      <td>-21.782121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791051</td>\n",
       "      <td>0.180148</td>\n",
       "      <td>-0.195515</td>\n",
       "      <td>-0.059862</td>\n",
       "      <td>0.091892</td>\n",
       "      <td>0.056669</td>\n",
       "      <td>-0.024036</td>\n",
       "      <td>-0.031334</td>\n",
       "      <td>0.023492</td>\n",
       "      <td>0.031977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "      <td>-300.014392</td>\n",
       "      <td>139.610539</td>\n",
       "      <td>-58.775005</td>\n",
       "      <td>-17.863993</td>\n",
       "      <td>-27.983239</td>\n",
       "      <td>-31.165856</td>\n",
       "      <td>-15.891464</td>\n",
       "      <td>-29.907360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625773</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>-0.158980</td>\n",
       "      <td>-0.015436</td>\n",
       "      <td>0.072798</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>0.033397</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>-0.038438</td>\n",
       "      <td>0.072341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24000</td>\n",
       "      <td>0</td>\n",
       "      <td>-313.237382</td>\n",
       "      <td>128.302576</td>\n",
       "      <td>-47.012209</td>\n",
       "      <td>19.925841</td>\n",
       "      <td>13.332181</td>\n",
       "      <td>-29.089705</td>\n",
       "      <td>-13.109960</td>\n",
       "      <td>-17.376589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469962</td>\n",
       "      <td>0.320646</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>-0.086741</td>\n",
       "      <td>0.068926</td>\n",
       "      <td>0.095494</td>\n",
       "      <td>0.023775</td>\n",
       "      <td>-0.018482</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.045553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampling_rate  label  mfcc_1_mean  mfcc_2_mean  mfcc_3_mean  mfcc_4_mean  \\\n",
       "0          24000      0  -392.408060   122.706493     4.529471    -1.131724   \n",
       "1          24000      1  -288.633987   150.553761   -51.823300     9.575870   \n",
       "2          24000      1  -321.349296   128.728553   -45.678164    16.015681   \n",
       "3          24000      1  -300.014392   139.610539   -58.775005   -17.863993   \n",
       "4          24000      0  -313.237382   128.302576   -47.012209    19.925841   \n",
       "\n",
       "   mfcc_5_mean  mfcc_6_mean  mfcc_7_mean  mfcc_8_mean  ...  lpc_3_mean  \\\n",
       "0    10.133050    -7.359573   -12.236763   -11.748826  ...    0.206947   \n",
       "1    16.140331   -25.634484    -9.063233   -13.583262  ...    0.942317   \n",
       "2     2.248679   -36.931314   -16.453398   -21.782121  ...    0.791051   \n",
       "3   -27.983239   -31.165856   -15.891464   -29.907360  ...    0.625773   \n",
       "4    13.332181   -29.089705   -13.109960   -17.376589  ...    0.469962   \n",
       "\n",
       "   lpc_4_mean  lpc_5_mean  lpc_6_mean  lpc_7_mean  lpc_8_mean  lpc_9_mean  \\\n",
       "0    0.242434    0.083058   -0.000745    0.017267    0.048853    0.049655   \n",
       "1    0.165730   -0.168018   -0.083517    0.020074    0.079114    0.045597   \n",
       "2    0.180148   -0.195515   -0.059862    0.091892    0.056669   -0.024036   \n",
       "3    0.182251   -0.158980   -0.015436    0.072798    0.026417    0.033397   \n",
       "4    0.320646   -0.054736   -0.086741    0.068926    0.095494    0.023775   \n",
       "\n",
       "   lpc_10_mean  lpc_11_mean  lpc_12_mean  \n",
       "0     0.011606    -0.013775     0.056669  \n",
       "1    -0.013818    -0.022306     0.027391  \n",
       "2    -0.031334     0.023492     0.031977  \n",
       "3     0.026217    -0.038438     0.072341  \n",
       "4    -0.018482     0.001961     0.045553  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'file_path' column\n",
    "data = df.drop(columns=['file_path'])\n",
    "\n",
    "# Convert 'label' column values from 'fake' and 'real' to 0 and 1\n",
    "data['label'] = data['label'].replace({'fake': 0, 'real': 1})\n",
    "\n",
    "# Display the updated dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 40)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and preprocess data\n",
    "features = data[['sampling_rate', 'mfcc_1_mean', 'mfcc_2_mean',\n",
    "       'mfcc_3_mean', 'mfcc_4_mean', 'mfcc_5_mean', 'mfcc_6_mean',\n",
    "       'mfcc_7_mean', 'mfcc_8_mean', 'mfcc_9_mean', 'mfcc_10_mean',\n",
    "       'mfcc_11_mean', 'mfcc_12_mean', 'mfcc_13_mean', 'chroma_1_mean',\n",
    "       'chroma_2_mean', 'chroma_3_mean', 'zcr_mean',\n",
    "       'spectral_contrast_1_mean', 'spectral_contrast_2_mean',\n",
    "       'spectral_contrast_3_mean', 'spectral_contrast_4_mean',\n",
    "       'spectral_contrast_5_mean', 'spectral_contrast_6_mean',\n",
    "       'spectral_centroid_mean', 'spectral_bandwidth_mean',\n",
    "       'spectral_rolloff_mean', 'lpc_1_mean', 'lpc_2_mean', 'lpc_3_mean',\n",
    "       'lpc_4_mean', 'lpc_5_mean', 'lpc_6_mean', 'lpc_7_mean', 'lpc_8_mean',\n",
    "       'lpc_9_mean', 'lpc_10_mean', 'lpc_11_mean', 'lpc_12_mean']] # Select features\n",
    "labels = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, sequence_length, overlap):\n",
    "    \"\"\"\n",
    "    Creates sequences from feature data.\n",
    "\n",
    "    Args:\n",
    "        features: A NumPy array of shape (num_samples, num_features).\n",
    "        sequence_length: The desired length of each sequence.\n",
    "        overlap: The number of overlapping features between consecutive sequences.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - A NumPy array of shape (num_sequences, sequence_length, num_features).\n",
    "            - A list of indices indicating the starting sample of each sequence.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    indices = []  # Store the starting index of each sequence\n",
    "    for i in range(0, len(features) - sequence_length + 1, sequence_length - overlap):\n",
    "        sequences.append(features[i: i + sequence_length])\n",
    "        indices.append(i)  # Store the starting index\n",
    "    return np.array(sequences), indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronan/Developer/deepfake-audio-detector/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.4837 - loss: 0.6951 - val_accuracy: 0.6042 - val_loss: 0.6771\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4921 - loss: 0.6952 - val_accuracy: 0.6042 - val_loss: 0.6753\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5545 - loss: 0.6868 - val_accuracy: 0.6042 - val_loss: 0.6805\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5292 - loss: 0.6916 - val_accuracy: 0.4167 - val_loss: 0.6932\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5037 - loss: 0.6918 - val_accuracy: 0.6875 - val_loss: 0.6822\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5102 - loss: 0.6903 - val_accuracy: 0.6042 - val_loss: 0.6714\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5244 - loss: 0.6880 - val_accuracy: 0.6667 - val_loss: 0.6788\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5613 - loss: 0.6902 - val_accuracy: 0.7500 - val_loss: 0.6817\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5271 - loss: 0.6895 - val_accuracy: 0.6458 - val_loss: 0.6722\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5383 - loss: 0.6914 - val_accuracy: 0.7500 - val_loss: 0.6777\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5993 - loss: 0.6828 - val_accuracy: 0.6458 - val_loss: 0.6686\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5402 - loss: 0.6835 - val_accuracy: 0.6875 - val_loss: 0.6719\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5668 - loss: 0.6808 - val_accuracy: 0.6667 - val_loss: 0.6726\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6116 - loss: 0.6707 - val_accuracy: 0.6458 - val_loss: 0.6538\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6142 - loss: 0.6643 - val_accuracy: 0.5833 - val_loss: 0.6851\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6028 - loss: 0.6501 - val_accuracy: 0.7292 - val_loss: 0.6520\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6028 - loss: 0.6529 - val_accuracy: 0.5417 - val_loss: 0.6806\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6748 - loss: 0.6129 - val_accuracy: 0.5833 - val_loss: 0.7149\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6495 - loss: 0.6256 - val_accuracy: 0.7083 - val_loss: 0.6126\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6765 - loss: 0.6196 - val_accuracy: 0.6875 - val_loss: 0.6512\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6816 - loss: 0.6074 - val_accuracy: 0.5833 - val_loss: 0.6420\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7082 - loss: 0.5935 - val_accuracy: 0.6250 - val_loss: 0.6467\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6849 - loss: 0.5960 - val_accuracy: 0.6042 - val_loss: 0.6874\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6743 - loss: 0.6044 - val_accuracy: 0.7083 - val_loss: 0.6238\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6654 - loss: 0.5849\n",
      "Test Loss: 0.6052702069282532\n",
      "Test Accuracy: 0.6583333611488342\n"
     ]
    }
   ],
   "source": [
    "# 1. Create sequences\n",
    "sequence_length = 10  # Example value, adjust as needed\n",
    "overlap = 5  # Example value, adjust as needed\n",
    "sequences, indices = create_sequences(features, sequence_length, overlap)\n",
    "labels = labels[indices]\n",
    "\n",
    "# 2. Pad sequences\n",
    "padded_sequences = pad_sequences(\n",
    "    sequences, maxlen=sequence_length, padding=\"pre\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "# Reshape padded_sequences for scaling\n",
    "num_samples, seq_len, num_features = padded_sequences.shape\n",
    "padded_sequences_reshaped = padded_sequences.reshape(\n",
    "    num_samples, seq_len * num_features\n",
    ")\n",
    "\n",
    "# Fit and transform the scaler on the reshaped data\n",
    "padded_sequences_scaled = scaler.fit_transform(padded_sequences_reshaped)\n",
    "\n",
    "# Reshape the scaled data back to the original shape\n",
    "padded_sequences = padded_sequences_scaled.reshape(\n",
    "    num_samples, seq_len, num_features\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(sequence_length, 40)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# 3. Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# 4. Train model with early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# 5. Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
